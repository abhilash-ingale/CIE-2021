{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69e40682",
   "metadata": {
    "code_folding": [
     13,
     23,
     32,
     40,
     60,
     70,
     80,
     90,
     96,
     119,
     138,
     187
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import resample\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_frequency(data):    \n",
    "    if(data.columns._data[0]=='Time (s)'):        \n",
    "        time = data['Time (s)']\n",
    "        num_entries = len(time)    \n",
    "        freq = (num_entries-1)/time[num_entries-2]\n",
    "        return freq\n",
    "    \n",
    "    elif(data.columns._data[0]=='Time(s)'):\n",
    "        time = data['Time(s)']\n",
    "    \n",
    "        num_entries = len(time)    \n",
    "        freq = (num_entries-1)/time[num_entries-2]\n",
    "        return freq\n",
    "    \n",
    "    else: \n",
    "        print(\"Data error\")\n",
    "\n",
    "# Butterwort filter\n",
    "def butterfilt_data(sensordata, fs=200, fc=5):\n",
    "    sensordata_filt = np.zeros(sensordata.shape)\n",
    "    w = 0.05\n",
    "    b, a = signal.butter(fc,w, 'low')\n",
    "    for i in range (3):\n",
    "        sensordata_filt[:,i] = signal.filtfilt(b,a, sensordata[:,i])  \n",
    "    return sensordata_filt\n",
    "\n",
    "#sg filter\n",
    "def sgfilt_data(sensordata, win_len = 51):\n",
    "    sensordata_filt = np.zeros(sensordata.shape)\n",
    "    if not(int(win_len)%2):\n",
    "        win_len -= 1\n",
    "    for i in range (0,3):\n",
    "        sensordata_filt[:,i] = signal.savgol_filter(sensordata[:,i], int(win_len), 2)\n",
    "    return sensordata_filt\n",
    "\n",
    "def cut_data(fil_data, freq):\n",
    "    gyr_abs = np.linalg.norm(fil_data,axis=1)\n",
    "    #determining the correct height still needs some playing/automation\n",
    "    #idea: get values of all peaks, take mean as value\n",
    "    #max_v = np.max(fil_data[:,0])\n",
    "    srt = np.sort(fil_data[:,0])    \n",
    "    max_v2 = srt[int(np.floor(0.95*len(srt)))]\n",
    "    peaks, _ = signal.find_peaks(gyr_abs,height=max_v2/2, distance=freq/2)\n",
    "    if len(peaks) <= 1: return [],[]\n",
    "    diff_peaks = np.diff(peaks)\n",
    "    n = int(np.ceil(len(diff_peaks)/5))\n",
    "    gap1  = np.argmax(diff_peaks[:n])\n",
    "    gap2  = np.argmax(diff_peaks[-n:])    \n",
    "    gap2  = int(gap2 + np.shape(diff_peaks)-n)    \n",
    "    gyr_cut = fil_data[peaks[gap1+1]:peaks[gap2],:]\n",
    "    gyr_cut_fil = fil_data\n",
    "    gyr_cut_fil[0:peaks[gap1],:] = 0    \n",
    "    gyr_cut_fil[peaks[gap2]:len(fil_data),:] = 0\n",
    "    return gyr_cut, gyr_cut_fil\n",
    "\n",
    "def rotate_data(gyr_cut):\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    rot_data = pca.fit_transform(gyr_cut)\n",
    "    a = pca.explained_variance_ratio_\n",
    "    b= pca.components_        \n",
    "    rot_data = MinMaxScaler().fit_transform(rot_data)       \n",
    "    return rot_data\n",
    "\n",
    "#just for testing the inbuilt rotation function, w returns the eigenvectors/principal components\n",
    "def pca_man(gyr_cut):    \n",
    "    x1 = np.mean(gyr_cut,axis=0)   \n",
    "    n = len(gyr_cut)\n",
    "    for i in range (0,n):\n",
    "        gyr_cut[i,:] -= x1    \n",
    "    X = np.transpose(gyr_cut)\n",
    "    J = np.identity(n)-1/n * np.ones(n)\n",
    "    C = np.matmul(np.matmul(X,J),np.transpose(np.matmul(X,J)))\n",
    "    w,v = np.linalg.eig(C)\n",
    "    \n",
    "def sample_data(data,freq) :\n",
    "    srt = np.sort(data[:,0])    \n",
    "    max_v2 = srt[int(np.floor(0.95*len(srt)))]\n",
    "    peaks, _ = signal.find_peaks(data[:,0],height = max_v2 * 0.9, distance=freq/2)\n",
    "    samples = []\n",
    "    for i in range (0,len(peaks)-1):        \n",
    "        sample = data[peaks[i]:peaks[i+1]+1,:]\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def resample_data(samples, n):\n",
    "    num_samples = len(samples)       \n",
    "    for i in range (0,num_samples):\n",
    "        samples[i] = resample(samples[i],n)\n",
    "    return samples\n",
    "\n",
    "def remove_bad_samples(samples,n, min_samples):\n",
    "    num_samples = len(samples)\n",
    "    data_per_time = np.empty((num_samples,n))\n",
    "    for i in range (0,num_samples):\n",
    "       for j in range (0,n):\n",
    "        data_per_time[i,j]=samples[i][j,0]\n",
    "    means = np.median(data_per_time,axis=0)\n",
    "    not_in_av = np.zeros((num_samples,n),dtype = bool)\n",
    "    for i in range (0,num_samples):\n",
    "       for j in range (0,n):\n",
    "           if(abs(data_per_time[i,j]-means[j]) > 0.2 * means[j]):\n",
    "               not_in_av[i,j] = 1\n",
    "    num_wrong = np.count_nonzero(not_in_av,axis=1)\n",
    "    to_be_removed = np.where(num_wrong > n * 0.3)   \n",
    "    c = 0\n",
    "    for i in to_be_removed[0]:        \n",
    "        del samples[i -c]\n",
    "        c = c+1\n",
    "    new_samples = []\n",
    "    if (len(samples)>=min_samples):\n",
    "        new_samples = random.sample(samples,min_samples)\n",
    "    return new_samples\n",
    "\n",
    "def get_cross_val_lists(path):\n",
    "    \n",
    "    folders = os.listdir(path)\n",
    "    \n",
    "    subject_list= []\n",
    "    for folder in folders:     \n",
    "        subject_list.append(folder[:10].lower())\n",
    "\n",
    "    unique_subject = list(set(subject_list))\n",
    "\n",
    "    folds_dict={}\n",
    "    for k_fold in [2,5,10]:\n",
    "        n = len(unique_subject)/k_fold\n",
    "        folds_dict['%s-fold' % k_fold] = {}\n",
    "        for i in range(0,k_fold,1):\n",
    "            folds_dict['%s-fold' % k_fold]['fold_%s' % i]= unique_subject[int(i*n):int((i+1)*n)]\n",
    "    \n",
    "    return folds_dict\n",
    "\n",
    "def preprocess_data(folder,data_path):\n",
    "    gyr_file = data_path + folder + '/Gyroscope.csv'\n",
    "    \n",
    "    if 'IMP' in folder.upper(): return 0,0\n",
    "    \n",
    "    if os.path.exists(gyr_file):  \n",
    "        #print(folder)\n",
    "        data_gyr = pd.read_csv(gyr_file)\n",
    "        data_gyr.dropna()\n",
    "        gyr = data_gyr.iloc[1:,1:4].values.astype(float)\n",
    "        #print(gyr_file)\n",
    "        #print(data_gyr)\n",
    "        fr = get_frequency(data_gyr)\n",
    "    \n",
    "        #filter noise\n",
    "        gyr_filt = butterfilt_data(gyr,fs = fr)\n",
    "        #gyr_filt = sgfilt_data(gyr,win_len = np.floor(fr/2))\n",
    "\n",
    "        #extract motion sequence\n",
    "        gyr_cut, gyr_cut_fil = cut_data(gyr_filt,fr)\n",
    "        #rotate\n",
    "        if(len(gyr_cut)==0): return 0,0\n",
    "        \n",
    "        rot_data = rotate_data(gyr_cut)\n",
    "        #rot_data = pca_man(gyr_cut)\n",
    "\n",
    "        #find samples\n",
    "        #this return a list with all samples and their data\n",
    "        samples = sample_data(rot_data,fr)\n",
    "        if (not samples): return 0,0\n",
    "        \n",
    "        #rescale samples to same frequency\n",
    "        n = 400\n",
    "        \n",
    "        samples = resample_data(samples,n)\n",
    "\n",
    "        #remove bad samples and data with too few samples\n",
    "        min_samples = 3\n",
    "        samples = remove_bad_samples(samples,n, min_samples)\n",
    "        if (not samples): return 0,0\n",
    "              \n",
    "            \n",
    "        if 'DO' in folder.upper():\n",
    "            labels = np.full(min_samples,0)\n",
    "        elif 'NO' in folder.upper():\n",
    "            labels = np.full(min_samples,1)\n",
    "        elif 'UP' in folder.upper():\n",
    "            labels = np.full(min_samples,2)\n",
    "        return samples, labels\n",
    "    else: \n",
    "        return 0,0\n",
    "\n",
    "def generate_numpy_arrays(fold_dict,data_path):\n",
    "    folders = os.listdir(data_path)\n",
    "    if not os.path.exists(\"arrays/\"):\n",
    "        os.makedirs(\"arrays/\")\n",
    "    else: \n",
    "        for k_fold in [2,5,10]:\n",
    "\n",
    "            #accuracy_results = []\n",
    "            for i in range(k_fold):\n",
    "                training_subjects= []\n",
    "                testing_subjects = []\n",
    "\n",
    "                testing_subjects = fold_dict['%s-fold' % k_fold]['fold_%s'% i]\n",
    "                print(i)\n",
    "                for x in range(k_fold):\n",
    "                    if x != i:\n",
    "                        training_subjects += fold_dict['%s-fold' % k_fold]['fold_%s'% x]\n",
    "                        print(x)\n",
    "\n",
    "                train_data = []\n",
    "                train_labels = []\n",
    "                test_data = []\n",
    "                test_labels = []\n",
    "\n",
    "                for folder in folders:\n",
    "                    if folder[:10].lower() in training_subjects:\n",
    "                        samples, labels = preprocess_data(folder,data_path) \n",
    "                        if samples == 0: continue \n",
    "                        train_data.append(samples)\n",
    "                        train_labels.append(labels)\n",
    "                    elif folder[:10].lower() in testing_subjects:\n",
    "                        samples, labels = preprocess_data(folder,data_path)\n",
    "                        if samples == 0: continue\n",
    "                        test_data.append(samples)\n",
    "                        test_labels.append(labels)\n",
    "                    else: continue\n",
    "\n",
    "                training_data = np.concatenate((np.asarray(train_data)),axis=0)\n",
    "                np.save('arrays/training_data_'+ '%s-fold_' % k_fold+'%s' %i,training_data)\n",
    "                training_labels = np.concatenate(train_labels)\n",
    "                np.save('arrays/training_labels_'+ '%s-fold_' % k_fold+'%s' %i,training_labels)\n",
    "                testing_data = np.concatenate(test_data)\n",
    "                np.save('arrays/testing_data_'+ '%s-fold_' % k_fold+'%s' %i,testing_data)\n",
    "                testing_labels = np.concatenate(test_labels)\n",
    "                np.save('arrays/testing_labels_'+ '%s-fold_' % k_fold+'%s' %i,testing_labels)\n",
    "                print('Generated and saved arrays for %s-fold cross validation:' % k_fold + 'fold number %s' % i)           \n",
    "\n",
    "def cross_validation_training(k_fold):\n",
    "    \n",
    "    accuracy_results = []\n",
    "    for i in range(k_fold):\n",
    "        training_data = np.load('arrays/training_data_'+ '%s-fold_' % k_fold+'%s' %i+'.npy')\n",
    "        training_labels = np.load('arrays/training_labels_'+ '%s-fold_' % k_fold+'%s' %i+'.npy')\n",
    "        testing_data = np.load('arrays/testing_data_'+ '%s-fold_' % k_fold+'%s' %i+'.npy')          \n",
    "        testing_labels = np.load('arrays/testing_labels_'+ '%s-fold_' % k_fold+'%s' %i+'.npy')\n",
    "        print('Training labels distribution:',np.unique(training_labels, return_index=False, return_inverse=False, return_counts=True, axis=None))\n",
    "        print('Testing labels distribution:',np.unique(testing_labels, return_index=False, return_inverse=False, return_counts=True, axis=None))\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(input_shape=(400,3)),\n",
    "                tf.keras.layers.Dense(100),\n",
    "                tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "                tf.keras.layers.Dropout(rate=0.25),\n",
    "                tf.keras.layers.Dense(50),\n",
    "                tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "                tf.keras.layers.Dense(3, activation ='softmax')\n",
    "                ])\n",
    "        \n",
    "        model_cnn = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                                                                       input_shape=(400,3)),\n",
    "                                                #tf.keras.layers.BatchNormalization(),\n",
    "                                                tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "                                                tf.keras.layers.Dropout(rate=0.10),\n",
    "                                                tf.keras.layers.Flatten(),\n",
    "                                                tf.keras.layers.Dense(50, activation ='relu'),\n",
    "                                                tf.keras.layers.Dense(3, activation ='softmax')])\n",
    "                        \n",
    "        \n",
    "        #Define early stop\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                  monitor=\"val_accuracy\",min_delta=0.05,\n",
    "                  patience=15,\n",
    "                  verbose=0)\n",
    "\n",
    "        epochs = 70\n",
    "        learning_rate = 5e-3\n",
    "        decay_rate = learning_rate / epochs\n",
    "        momentum = 0.85\n",
    "        \n",
    "        # Compile model\n",
    "        #model.compile(loss='sparse_categorical_crossentropy', \n",
    "        #              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "        #              metrics=['accuracy'])\n",
    "        \n",
    "        model_cnn.compile(loss='sparse_categorical_crossentropy', \n",
    "                      optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate,momentum=momentum, decay=decay_rate, nesterov=False), \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "        history = model_cnn.fit(training_data,training_labels,validation_data=(testing_data,testing_labels), \n",
    "                                batch_size = 8,epochs = epochs,\n",
    "                               callbacks=early_stop)\n",
    "\n",
    "        accuracy_results.append(np.max(history.history['val_accuracy']))\n",
    "        #plt.plot(history.history['loss'])\n",
    "        #plt.plot(history.history['val_loss'])\n",
    "        #plt.title('Loss')\n",
    "        #plt.ylabel('loss')\n",
    "        #plt.xlabel('epoch')\n",
    "        #plt.legend(['train', 'test'], loc='upper right')\n",
    "        #plt.show()\n",
    "\n",
    "    print('Best validation accuracy:', np.max(accuracy_results))\n",
    "    print(accuracy_results)\n",
    "    print('Mean validation accuracy:', np.mean(accuracy_results))\n",
    "    return accuracy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8d470",
   "metadata": {},
   "source": [
    "### You only need to run the following cell once to generate and save the numpy arrays for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b29c2d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Generated and saved arrays for 2-fold cross validation:fold number 0\n",
      "1\n",
      "0\n",
      "Generated and saved arrays for 2-fold cross validation:fold number 1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Generated and saved arrays for 5-fold cross validation:fold number 0\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "Generated and saved arrays for 5-fold cross validation:fold number 1\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "Generated and saved arrays for 5-fold cross validation:fold number 2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "Generated and saved arrays for 5-fold cross validation:fold number 3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Generated and saved arrays for 5-fold cross validation:fold number 4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 0\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 1\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 6\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 7\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Generated and saved arrays for 10-fold cross validation:fold number 9\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:/Users/admin/Documents/01_RWTH Courses/03_ WiSe21/CIE/Project A/Data/All data/Smartphone1Copy/'\n",
    "#obtain distribution of subjects per fold\n",
    "fold_dict = get_cross_val_lists(data_path)\n",
    "#function that generates and saves the numpy arrays\n",
    "generate_numpy_arrays(fold_dict,data_path)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf9639",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4eaa6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to change the parameters you need to go to the cross_validation_training function\n",
    "#There you can and should change the following parameters:\n",
    "#number of neurons in each layer, number of layers, activation functions, patience on the early stopping,\n",
    "#learning_rate, batch_size, epochs\n",
    "#The relevant value for the accuracy of a model(or whatever metrics you use) is the mean value between all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4309d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels distribution: (array([0, 1, 2]), array([144, 249, 186], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([141, 255, 210], dtype=int64))\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.9829 - accuracy: 0.4767 - val_loss: 0.7065 - val_accuracy: 0.6122\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7150 - accuracy: 0.6563 - val_loss: 0.5369 - val_accuracy: 0.8152\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.6213 - accuracy: 0.7358 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.5662 - accuracy: 0.7703 - val_loss: 0.5010 - val_accuracy: 0.7855\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.5100 - accuracy: 0.7910 - val_loss: 0.4488 - val_accuracy: 0.8218\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4491 - accuracy: 0.8290 - val_loss: 0.4097 - val_accuracy: 0.8267\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.4149 - accuracy: 0.8359 - val_loss: 0.3984 - val_accuracy: 0.8432\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.3957 - accuracy: 0.8497 - val_loss: 0.4178 - val_accuracy: 0.8465\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.3817 - accuracy: 0.8566 - val_loss: 0.4095 - val_accuracy: 0.8383\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.3157 - accuracy: 0.8877 - val_loss: 0.4056 - val_accuracy: 0.8416\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.2740 - accuracy: 0.8964 - val_loss: 0.4473 - val_accuracy: 0.8267\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.2719 - accuracy: 0.8946 - val_loss: 0.5035 - val_accuracy: 0.8432\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.2150 - accuracy: 0.9292 - val_loss: 0.3957 - val_accuracy: 0.8449\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.1783 - accuracy: 0.9361 - val_loss: 0.5598 - val_accuracy: 0.8218\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.2015 - accuracy: 0.9292 - val_loss: 0.4944 - val_accuracy: 0.8218\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.1771 - accuracy: 0.9413 - val_loss: 0.4791 - val_accuracy: 0.8152\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.1423 - accuracy: 0.9482 - val_loss: 0.5888 - val_accuracy: 0.8234\n",
      "Training labels distribution: (array([0, 1, 2]), array([141, 255, 210], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([144, 249, 186], dtype=int64))\n",
      "Epoch 1/70\n",
      "76/76 [==============================] - 2s 17ms/step - loss: 0.9405 - accuracy: 0.5033 - val_loss: 0.8000 - val_accuracy: 0.5838\n",
      "Epoch 2/70\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.4976 - accuracy: 0.8003 - val_loss: 0.8703 - val_accuracy: 0.7306\n",
      "Epoch 3/70\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.4029 - accuracy: 0.8581 - val_loss: 0.8337 - val_accuracy: 0.7271\n",
      "Epoch 4/70\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.3504 - accuracy: 0.8680 - val_loss: 0.7793 - val_accuracy: 0.7185\n",
      "Epoch 5/70\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.3559 - accuracy: 0.8663 - val_loss: 0.7865 - val_accuracy: 0.7703\n",
      "Epoch 6/70\n",
      "76/76 [==============================] - 1s 20ms/step - loss: 0.3369 - accuracy: 0.8762 - val_loss: 0.7540 - val_accuracy: 0.7513\n",
      "Epoch 7/70\n",
      "76/76 [==============================] - 2s 20ms/step - loss: 0.3064 - accuracy: 0.8812 - val_loss: 0.8102 - val_accuracy: 0.7651\n",
      "Epoch 8/70\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2861 - accuracy: 0.8993 - val_loss: 0.7849 - val_accuracy: 0.7737\n",
      "Epoch 9/70\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2399 - accuracy: 0.9356 - val_loss: 0.8978 - val_accuracy: 0.7617\n",
      "Epoch 10/70\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2401 - accuracy: 0.9092 - val_loss: 1.1415 - val_accuracy: 0.6753\n",
      "Epoch 11/70\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2438 - accuracy: 0.9158 - val_loss: 1.0342 - val_accuracy: 0.7651\n",
      "Epoch 12/70\n",
      "76/76 [==============================] - 2s 20ms/step - loss: 0.2491 - accuracy: 0.9158 - val_loss: 0.8964 - val_accuracy: 0.7720\n",
      "Epoch 13/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2136 - accuracy: 0.9191 - val_loss: 0.9264 - val_accuracy: 0.7617\n",
      "Epoch 14/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.1931 - accuracy: 0.9323 - val_loss: 0.9900 - val_accuracy: 0.7651\n",
      "Epoch 15/70\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.1528 - accuracy: 0.9488 - val_loss: 1.0008 - val_accuracy: 0.7547\n",
      "Epoch 16/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.1760 - accuracy: 0.9307 - val_loss: 0.9425 - val_accuracy: 0.7807\n",
      "Epoch 17/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.1444 - accuracy: 0.9472 - val_loss: 1.0599 - val_accuracy: 0.7599\n",
      "Epoch 18/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.1469 - accuracy: 0.9422 - val_loss: 0.8923 - val_accuracy: 0.7772\n",
      "Epoch 19/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.1591 - accuracy: 0.9472 - val_loss: 0.8695 - val_accuracy: 0.7893\n",
      "Epoch 20/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.1076 - accuracy: 0.9587 - val_loss: 0.9130 - val_accuracy: 0.7945\n",
      "Epoch 21/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0828 - accuracy: 0.9703 - val_loss: 1.0863 - val_accuracy: 0.7807\n",
      "Epoch 22/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.1330 - accuracy: 0.9620 - val_loss: 0.9435 - val_accuracy: 0.7910\n",
      "Epoch 23/70\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 1.0205 - val_accuracy: 0.7927\n",
      "Epoch 24/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0578 - accuracy: 0.9835 - val_loss: 1.0425 - val_accuracy: 0.7962\n",
      "Epoch 25/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0918 - accuracy: 0.9554 - val_loss: 0.9750 - val_accuracy: 0.7945\n",
      "Epoch 26/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0810 - accuracy: 0.9587 - val_loss: 0.9746 - val_accuracy: 0.7962\n",
      "Epoch 27/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0701 - accuracy: 0.9719 - val_loss: 1.1783 - val_accuracy: 0.7824\n",
      "Epoch 28/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0512 - accuracy: 0.9802 - val_loss: 1.0930 - val_accuracy: 0.7962\n",
      "Epoch 29/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0415 - accuracy: 0.9901 - val_loss: 1.2249 - val_accuracy: 0.7876\n",
      "Epoch 30/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0460 - accuracy: 0.9785 - val_loss: 1.1812 - val_accuracy: 0.7841\n",
      "Epoch 31/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0150 - accuracy: 0.9983 - val_loss: 1.1888 - val_accuracy: 0.7945\n",
      "Best validation accuracy: 0.8465346693992615\n",
      "[0.8465346693992615, 0.7962003350257874]\n",
      "Mean validation accuracy: 0.8213675022125244\n",
      "Mean accuracy for 2-fold: 0.8213675022125244\n",
      "-------------------------DONE------------------------\n"
     ]
    }
   ],
   "source": [
    "#Do one at a time if you prefer\n",
    "accuracy_results_2fold = cross_validation_training(k_fold=2)\n",
    "print('Mean accuracy for 2-fold: %s' % np.mean(accuracy_results_2fold))\n",
    "print(\"-------------------------DONE------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27be8e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels distribution: (array([0, 1, 2]), array([225, 414, 315], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([60, 90, 81], dtype=int64))\n",
      "Epoch 1/70\n",
      "120/120 [==============================] - 3s 14ms/step - loss: 0.8668 - accuracy: 0.5660 - val_loss: 0.5258 - val_accuracy: 0.8052\n",
      "Epoch 2/70\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.6012 - accuracy: 0.7579 - val_loss: 0.4912 - val_accuracy: 0.8095\n",
      "Epoch 3/70\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.5397 - accuracy: 0.7820 - val_loss: 0.4191 - val_accuracy: 0.8528\n",
      "Epoch 4/70\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.4938 - accuracy: 0.7935 - val_loss: 0.4458 - val_accuracy: 0.8442\n",
      "Epoch 5/70\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.4381 - accuracy: 0.8333 - val_loss: 0.4534 - val_accuracy: 0.8182\n",
      "Epoch 6/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.4081 - accuracy: 0.8291 - val_loss: 0.4778 - val_accuracy: 0.8442\n",
      "Epoch 7/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.3482 - accuracy: 0.8742 - val_loss: 0.7588 - val_accuracy: 0.7013\n",
      "Epoch 8/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.3378 - accuracy: 0.8637 - val_loss: 0.4823 - val_accuracy: 0.8745\n",
      "Epoch 9/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.3130 - accuracy: 0.8784 - val_loss: 0.5179 - val_accuracy: 0.8355\n",
      "Epoch 10/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.2933 - accuracy: 0.8962 - val_loss: 0.3557 - val_accuracy: 0.8658\n",
      "Epoch 11/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.2695 - accuracy: 0.8983 - val_loss: 0.5183 - val_accuracy: 0.8355\n",
      "Epoch 12/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.2299 - accuracy: 0.9161 - val_loss: 0.4022 - val_accuracy: 0.8788\n",
      "Epoch 13/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.2433 - accuracy: 0.9078 - val_loss: 0.4700 - val_accuracy: 0.8442\n",
      "Epoch 14/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1923 - accuracy: 0.9319 - val_loss: 0.5432 - val_accuracy: 0.8701\n",
      "Epoch 15/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1592 - accuracy: 0.9423 - val_loss: 0.4673 - val_accuracy: 0.8442\n",
      "Epoch 16/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1578 - accuracy: 0.9497 - val_loss: 0.5602 - val_accuracy: 0.8788\n",
      "Epoch 17/70\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.1894 - accuracy: 0.9340 - val_loss: 0.5412 - val_accuracy: 0.8398\n",
      "Epoch 18/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1508 - accuracy: 0.9591 - val_loss: 0.6358 - val_accuracy: 0.8485\n",
      "Epoch 19/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1699 - accuracy: 0.9444 - val_loss: 0.4819 - val_accuracy: 0.8788\n",
      "Epoch 20/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1337 - accuracy: 0.9539 - val_loss: 0.6553 - val_accuracy: 0.8745\n",
      "Epoch 21/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1050 - accuracy: 0.9654 - val_loss: 0.6046 - val_accuracy: 0.8615\n",
      "Epoch 22/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 0.5247 - val_accuracy: 0.8701\n",
      "Epoch 23/70\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0945 - accuracy: 0.9727 - val_loss: 0.7421 - val_accuracy: 0.8788\n",
      "Training labels distribution: (array([0, 1, 2]), array([237, 387, 315], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([ 48, 117,  81], dtype=int64))\n",
      "Epoch 1/70\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.8054 - accuracy: 0.6219 - val_loss: 0.4565 - val_accuracy: 0.7927\n",
      "Epoch 2/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.6243 - accuracy: 0.7583 - val_loss: 0.4276 - val_accuracy: 0.8008\n",
      "Epoch 3/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.5591 - accuracy: 0.7881 - val_loss: 0.3573 - val_accuracy: 0.8455\n",
      "Epoch 4/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.5209 - accuracy: 0.7881 - val_loss: 0.3207 - val_accuracy: 0.8659\n",
      "Epoch 5/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.4810 - accuracy: 0.8040 - val_loss: 0.3585 - val_accuracy: 0.8455\n",
      "Epoch 6/70\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.4460 - accuracy: 0.8232 - val_loss: 0.5560 - val_accuracy: 0.7846\n",
      "Epoch 7/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.4501 - accuracy: 0.8360 - val_loss: 0.3009 - val_accuracy: 0.8740\n",
      "Epoch 8/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.3784 - accuracy: 0.8520 - val_loss: 0.3415 - val_accuracy: 0.8659\n",
      "Epoch 9/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.3601 - accuracy: 0.8701 - val_loss: 0.2990 - val_accuracy: 0.8659\n",
      "Epoch 10/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.3215 - accuracy: 0.8882 - val_loss: 0.2993 - val_accuracy: 0.8902\n",
      "Epoch 11/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.3081 - accuracy: 0.8892 - val_loss: 0.2728 - val_accuracy: 0.9146\n",
      "Epoch 12/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2594 - accuracy: 0.9031 - val_loss: 0.2541 - val_accuracy: 0.8902\n",
      "Epoch 13/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2502 - accuracy: 0.9073 - val_loss: 0.2905 - val_accuracy: 0.8821\n",
      "Epoch 14/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2324 - accuracy: 0.9148 - val_loss: 0.2354 - val_accuracy: 0.9146\n",
      "Epoch 15/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1964 - accuracy: 0.9318 - val_loss: 0.2374 - val_accuracy: 0.8862\n",
      "Epoch 16/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2194 - accuracy: 0.9223 - val_loss: 0.2837 - val_accuracy: 0.9106\n",
      "Epoch 17/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1709 - accuracy: 0.9414 - val_loss: 0.2707 - val_accuracy: 0.8943\n",
      "Epoch 18/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1771 - accuracy: 0.9425 - val_loss: 0.2679 - val_accuracy: 0.8984\n",
      "Epoch 19/70\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.95 - 1s 12ms/step - loss: 0.1259 - accuracy: 0.9585 - val_loss: 0.2380 - val_accuracy: 0.8984\n",
      "Epoch 20/70\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.1431 - accuracy: 0.9457 - val_loss: 0.3028 - val_accuracy: 0.8821\n",
      "Epoch 21/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1005 - accuracy: 0.9681 - val_loss: 0.3197 - val_accuracy: 0.8821\n",
      "Epoch 22/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1330 - accuracy: 0.9542 - val_loss: 0.2135 - val_accuracy: 0.9146\n",
      "Epoch 23/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0828 - accuracy: 0.9702 - val_loss: 0.3290 - val_accuracy: 0.8821\n",
      "Epoch 24/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.3149 - val_accuracy: 0.9024\n",
      "Epoch 25/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0736 - accuracy: 0.9755 - val_loss: 0.3093 - val_accuracy: 0.8943\n",
      "Epoch 26/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0465 - accuracy: 0.9840 - val_loss: 0.3515 - val_accuracy: 0.8902\n",
      "Training labels distribution: (array([0, 1, 2]), array([225, 408, 306], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([60, 96, 90], dtype=int64))\n",
      "Epoch 1/70\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.8390 - accuracy: 0.5900 - val_loss: 0.6829 - val_accuracy: 0.6667\n",
      "Epoch 2/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5629 - accuracy: 0.7625 - val_loss: 0.6897 - val_accuracy: 0.7520\n",
      "Epoch 3/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.4610 - accuracy: 0.8072 - val_loss: 0.5315 - val_accuracy: 0.8008\n",
      "Epoch 4/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.4166 - accuracy: 0.8253 - val_loss: 0.7184 - val_accuracy: 0.6423\n",
      "Epoch 5/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 1s 11ms/step - loss: 0.3880 - accuracy: 0.8403 - val_loss: 0.5746 - val_accuracy: 0.7561\n",
      "Epoch 6/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.3582 - accuracy: 0.8562 - val_loss: 0.5223 - val_accuracy: 0.7967\n",
      "Epoch 7/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.3351 - accuracy: 0.8637 - val_loss: 0.5284 - val_accuracy: 0.8252\n",
      "Epoch 8/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.3111 - accuracy: 0.8786 - val_loss: 0.5746 - val_accuracy: 0.7886\n",
      "Epoch 9/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2719 - accuracy: 0.9020 - val_loss: 0.5424 - val_accuracy: 0.8130\n",
      "Epoch 10/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2311 - accuracy: 0.9063 - val_loss: 0.6265 - val_accuracy: 0.8049\n",
      "Epoch 11/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2066 - accuracy: 0.9212 - val_loss: 0.5924 - val_accuracy: 0.8171\n",
      "Epoch 12/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2220 - accuracy: 0.9201 - val_loss: 0.5311 - val_accuracy: 0.8252\n",
      "Epoch 13/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2027 - accuracy: 0.9244 - val_loss: 0.5391 - val_accuracy: 0.8333\n",
      "Epoch 14/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9276 - val_loss: 0.5187 - val_accuracy: 0.8130\n",
      "Epoch 15/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1600 - accuracy: 0.9340 - val_loss: 0.6435 - val_accuracy: 0.8211\n",
      "Epoch 16/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1340 - accuracy: 0.9553 - val_loss: 0.6250 - val_accuracy: 0.8008\n",
      "Epoch 17/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1243 - accuracy: 0.9553 - val_loss: 0.7134 - val_accuracy: 0.7805\n",
      "Epoch 18/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1233 - accuracy: 0.9553 - val_loss: 0.6336 - val_accuracy: 0.7846\n",
      "Epoch 19/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1165 - accuracy: 0.9595 - val_loss: 0.5846 - val_accuracy: 0.8374\n",
      "Epoch 20/70\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0898 - accuracy: 0.9702 - val_loss: 0.7414 - val_accuracy: 0.7846\n",
      "Epoch 21/70\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 0.5937 - val_accuracy: 0.8252\n",
      "Epoch 22/70\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0820 - accuracy: 0.9723 - val_loss: 0.7712 - val_accuracy: 0.8252\n",
      "Training labels distribution: (array([0, 1, 2]), array([216, 408, 321], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([69, 96, 75], dtype=int64))\n",
      "Epoch 1/70\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.7718 - accuracy: 0.6381 - val_loss: 0.7768 - val_accuracy: 0.7250\n",
      "Epoch 2/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.5330 - accuracy: 0.7926 - val_loss: 0.7578 - val_accuracy: 0.7542\n",
      "Epoch 3/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.5139 - accuracy: 0.8042 - val_loss: 0.7754 - val_accuracy: 0.7333\n",
      "Epoch 4/70\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.4399 - accuracy: 0.8402 - val_loss: 0.6843 - val_accuracy: 0.7750\n",
      "Epoch 5/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.4405 - accuracy: 0.8328 - val_loss: 0.6595 - val_accuracy: 0.7333\n",
      "Epoch 6/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.3767 - accuracy: 0.8497 - val_loss: 0.6775 - val_accuracy: 0.7500\n",
      "Epoch 7/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.3606 - accuracy: 0.8508 - val_loss: 0.7027 - val_accuracy: 0.7625\n",
      "Epoch 8/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.3296 - accuracy: 0.8762 - val_loss: 0.7231 - val_accuracy: 0.7542\n",
      "Epoch 9/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.2933 - accuracy: 0.8963 - val_loss: 0.6153 - val_accuracy: 0.7750\n",
      "Epoch 10/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.3118 - accuracy: 0.8815 - val_loss: 0.6611 - val_accuracy: 0.7708\n",
      "Epoch 11/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.2578 - accuracy: 0.9164 - val_loss: 0.6618 - val_accuracy: 0.7708\n",
      "Epoch 12/70\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.2382 - accuracy: 0.9238 - val_loss: 0.6616 - val_accuracy: 0.7667\n",
      "Epoch 13/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1942 - accuracy: 0.9365 - val_loss: 0.8167 - val_accuracy: 0.7125\n",
      "Epoch 14/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1952 - accuracy: 0.9333 - val_loss: 0.9390 - val_accuracy: 0.7292\n",
      "Epoch 15/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.2022 - accuracy: 0.9270 - val_loss: 0.7100 - val_accuracy: 0.7750\n",
      "Epoch 16/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9365 - val_loss: 0.6147 - val_accuracy: 0.8125\n",
      "Epoch 17/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1166 - accuracy: 0.9672 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
      "Epoch 18/70\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.1234 - accuracy: 0.9587 - val_loss: 0.8316 - val_accuracy: 0.7458\n",
      "Epoch 19/70\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1495 - accuracy: 0.9471 - val_loss: 0.6860 - val_accuracy: 0.8042\n",
      "Epoch 20/70\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.0840 - accuracy: 0.9799 - val_loss: 0.8256 - val_accuracy: 0.8000\n",
      "Epoch 21/70\n",
      "119/119 [==============================] - 2s 16ms/step - loss: 0.1296 - accuracy: 0.9471 - val_loss: 0.6924 - val_accuracy: 0.7958\n",
      "Epoch 22/70\n",
      "119/119 [==============================] - 2s 14ms/step - loss: 0.0783 - accuracy: 0.9799 - val_loss: 0.6974 - val_accuracy: 0.8042\n",
      "Epoch 23/70\n",
      "119/119 [==============================] - 2s 14ms/step - loss: 0.0709 - accuracy: 0.9778 - val_loss: 0.7243 - val_accuracy: 0.8167\n",
      "Epoch 24/70\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 0.0685 - accuracy: 0.9799 - val_loss: 0.8185 - val_accuracy: 0.7917\n",
      "Epoch 25/70\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.0476 - accuracy: 0.9884 - val_loss: 0.7679 - val_accuracy: 0.8208\n",
      "Epoch 26/70\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.7640 - val_accuracy: 0.8000\n",
      "Epoch 27/70\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.8271 - val_accuracy: 0.8083\n",
      "Epoch 28/70\n",
      "119/119 [==============================] - 2s 14ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.8319 - val_accuracy: 0.8000\n",
      "Epoch 29/70\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.9606 - val_accuracy: 0.7750\n",
      "Epoch 30/70\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.9008 - val_accuracy: 0.7875\n",
      "Epoch 31/70\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.9586 - val_accuracy: 0.8083\n",
      "Training labels distribution: (array([0, 1, 2]), array([237, 399, 327], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([ 48, 105,  69], dtype=int64))\n",
      "Epoch 1/70\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.8422 - accuracy: 0.5919 - val_loss: 0.6348 - val_accuracy: 0.7703\n",
      "Epoch 2/70\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.5636 - accuracy: 0.7549 - val_loss: 0.5802 - val_accuracy: 0.8153\n",
      "Epoch 3/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.4901 - accuracy: 0.7985 - val_loss: 0.6073 - val_accuracy: 0.7838\n",
      "Epoch 4/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.4618 - accuracy: 0.8204 - val_loss: 0.4768 - val_accuracy: 0.7883\n",
      "Epoch 5/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.4055 - accuracy: 0.8546 - val_loss: 0.4350 - val_accuracy: 0.8378\n",
      "Epoch 6/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.3737 - accuracy: 0.8588 - val_loss: 0.4522 - val_accuracy: 0.8423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/70\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.3194 - accuracy: 0.8889 - val_loss: 0.4343 - val_accuracy: 0.8288\n",
      "Epoch 8/70\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.3004 - accuracy: 0.8827 - val_loss: 0.5458 - val_accuracy: 0.7477\n",
      "Epoch 9/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.2789 - accuracy: 0.8941 - val_loss: 0.4762 - val_accuracy: 0.8288\n",
      "Epoch 10/70\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.2480 - accuracy: 0.9003 - val_loss: 0.4553 - val_accuracy: 0.8423\n",
      "Epoch 11/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.2141 - accuracy: 0.9263 - val_loss: 0.4436 - val_accuracy: 0.8333\n",
      "Epoch 12/70\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.2061 - accuracy: 0.9117 - val_loss: 0.5024 - val_accuracy: 0.8468\n",
      "Epoch 13/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.1669 - accuracy: 0.9429 - val_loss: 0.4442 - val_accuracy: 0.8378\n",
      "Epoch 14/70\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.1682 - accuracy: 0.9346 - val_loss: 0.6626 - val_accuracy: 0.8198\n",
      "Epoch 15/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.1266 - accuracy: 0.9533 - val_loss: 0.5411 - val_accuracy: 0.8288\n",
      "Epoch 16/70\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.1063 - accuracy: 0.9637 - val_loss: 0.4462 - val_accuracy: 0.8739\n",
      "Epoch 17/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0855 - accuracy: 0.9709 - val_loss: 0.5541 - val_accuracy: 0.8468\n",
      "Epoch 18/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9616 - val_loss: 0.5855 - val_accuracy: 0.8649\n",
      "Epoch 19/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0748 - accuracy: 0.9720 - val_loss: 0.5112 - val_accuracy: 0.8604\n",
      "Epoch 20/70\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0864 - accuracy: 0.9688 - val_loss: 0.4150 - val_accuracy: 0.8784\n",
      "Best validation accuracy: 0.9146341681480408\n",
      "[0.8787878751754761, 0.9146341681480408, 0.8373983502388, 0.8208333253860474, 0.8783783912658691]\n",
      "Mean validation accuracy: 0.8660064220428467\n",
      "Mean accuracy for 5-fold: 0.8660064220428467\n",
      "-------------------------DONE------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracy_results_5fold = cross_validation_training(k_fold=5)\n",
    "print('Mean accuracy for 5-fold: %s' % np.mean(accuracy_results_5fold))\n",
    "print(\"-------------------------DONE------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da51bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels distribution: (array([0, 1, 2]), array([264, 462, 360], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([21, 42, 36], dtype=int64))\n",
      "Epoch 1/70\n",
      "136/136 [==============================] - 3s 15ms/step - loss: 0.8142 - accuracy: 0.6077 - val_loss: 0.5453 - val_accuracy: 0.8081\n",
      "Epoch 2/70\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.5690 - accuracy: 0.7716 - val_loss: 0.5636 - val_accuracy: 0.8283\n",
      "Epoch 3/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.5056 - accuracy: 0.7947 - val_loss: 0.4254 - val_accuracy: 0.8283\n",
      "Epoch 4/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.4506 - accuracy: 0.7993 - val_loss: 0.4438 - val_accuracy: 0.8687\n",
      "Epoch 5/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.4232 - accuracy: 0.8278 - val_loss: 0.4436 - val_accuracy: 0.8081\n",
      "Epoch 6/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.3735 - accuracy: 0.8481 - val_loss: 0.3985 - val_accuracy: 0.8384\n",
      "Epoch 7/70\n",
      "136/136 [==============================] - 2s 13ms/step - loss: 0.3378 - accuracy: 0.8720 - val_loss: 0.4432 - val_accuracy: 0.8182\n",
      "Epoch 8/70\n",
      "136/136 [==============================] - 2s 15ms/step - loss: 0.2905 - accuracy: 0.8950 - val_loss: 0.5233 - val_accuracy: 0.7778\n",
      "Epoch 9/70\n",
      "136/136 [==============================] - 2s 14ms/step - loss: 0.2555 - accuracy: 0.9061 - val_loss: 0.4635 - val_accuracy: 0.8182\n",
      "Epoch 10/70\n",
      "136/136 [==============================] - 2s 14ms/step - loss: 0.2441 - accuracy: 0.9217 - val_loss: 0.6016 - val_accuracy: 0.8283\n",
      "Epoch 11/70\n",
      "136/136 [==============================] - 2s 14ms/step - loss: 0.2081 - accuracy: 0.9254 - val_loss: 0.5565 - val_accuracy: 0.8283\n",
      "Epoch 12/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2056 - accuracy: 0.9254 - val_loss: 0.3641 - val_accuracy: 0.8788\n",
      "Epoch 13/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9392 - val_loss: 0.3203 - val_accuracy: 0.8990\n",
      "Epoch 14/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.1469 - accuracy: 0.9503 - val_loss: 0.4877 - val_accuracy: 0.8687\n",
      "Epoch 15/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.1235 - accuracy: 0.9549 - val_loss: 0.5586 - val_accuracy: 0.8586\n",
      "Epoch 16/70\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.1192 - accuracy: 0.9521 - val_loss: 0.4165 - val_accuracy: 0.8889\n",
      "Epoch 17/70\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.1058 - accuracy: 0.9604 - val_loss: 0.3622 - val_accuracy: 0.9091\n",
      "Epoch 18/70\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.0834 - accuracy: 0.9678 - val_loss: 0.4679 - val_accuracy: 0.8889\n",
      "Epoch 19/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.0871 - accuracy: 0.9659 - val_loss: 0.6300 - val_accuracy: 0.8586\n",
      "Training labels distribution: (array([0, 1, 2]), array([246, 456, 351], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([39, 48, 45], dtype=int64))\n",
      "Epoch 1/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.8682 - accuracy: 0.5745 - val_loss: 0.5150 - val_accuracy: 0.8182\n",
      "Epoch 2/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5781 - accuracy: 0.7702 - val_loss: 0.4611 - val_accuracy: 0.8636\n",
      "Epoch 3/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5209 - accuracy: 0.7835 - val_loss: 0.5478 - val_accuracy: 0.7955\n",
      "Epoch 4/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.4770 - accuracy: 0.8072 - val_loss: 0.3979 - val_accuracy: 0.8561\n",
      "Epoch 5/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4420 - accuracy: 0.8205 - val_loss: 0.5120 - val_accuracy: 0.8258\n",
      "Epoch 6/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4626 - accuracy: 0.8044 - val_loss: 0.4458 - val_accuracy: 0.8485\n",
      "Epoch 7/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3757 - accuracy: 0.8538 - val_loss: 0.4280 - val_accuracy: 0.8561\n",
      "Epoch 8/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3619 - accuracy: 0.8500 - val_loss: 0.3995 - val_accuracy: 0.8712\n",
      "Epoch 9/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3361 - accuracy: 0.8623 - val_loss: 0.5221 - val_accuracy: 0.8636\n",
      "Epoch 10/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3035 - accuracy: 0.8756 - val_loss: 0.4881 - val_accuracy: 0.8712\n",
      "Epoch 11/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2925 - accuracy: 0.8898 - val_loss: 0.6423 - val_accuracy: 0.8030\n",
      "Epoch 12/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2437 - accuracy: 0.9060 - val_loss: 0.5927 - val_accuracy: 0.7879\n",
      "Epoch 13/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.2533 - accuracy: 0.9050 - val_loss: 0.4619 - val_accuracy: 0.8409\n",
      "Epoch 14/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2449 - accuracy: 0.9069 - val_loss: 0.9572 - val_accuracy: 0.8106\n",
      "Epoch 15/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.7964 - val_accuracy: 0.8864\n",
      "Epoch 16/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1995 - accuracy: 0.9259 - val_loss: 0.6041 - val_accuracy: 0.8182\n",
      "Epoch 17/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1546 - accuracy: 0.9497 - val_loss: 0.7491 - val_accuracy: 0.8485\n",
      "Epoch 18/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1408 - accuracy: 0.9487 - val_loss: 0.7942 - val_accuracy: 0.8182\n",
      "Epoch 19/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1594 - accuracy: 0.9497 - val_loss: 0.6194 - val_accuracy: 0.8636\n",
      "Epoch 20/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1368 - accuracy: 0.9544 - val_loss: 0.5522 - val_accuracy: 0.8788\n",
      "Epoch 21/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1009 - accuracy: 0.9630 - val_loss: 0.6792 - val_accuracy: 0.8030\n",
      "Epoch 22/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.0937 - accuracy: 0.9668 - val_loss: 0.7344 - val_accuracy: 0.8485\n",
      "Epoch 23/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.0900 - accuracy: 0.9734 - val_loss: 0.8548 - val_accuracy: 0.8788\n",
      "Training labels distribution: (array([0, 1, 2]), array([273, 447, 366], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([12, 57, 30], dtype=int64))\n",
      "Epoch 1/70\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 0.8480 - accuracy: 0.5856 - val_loss: 0.7681 - val_accuracy: 0.6667\n",
      "Epoch 2/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.6068 - accuracy: 0.7587 - val_loss: 0.3850 - val_accuracy: 0.7980\n",
      "Epoch 3/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.5142 - accuracy: 0.8149 - val_loss: 0.2840 - val_accuracy: 0.9091\n",
      "Epoch 4/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.4627 - accuracy: 0.8195 - val_loss: 0.3840 - val_accuracy: 0.8182\n",
      "Epoch 5/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.4157 - accuracy: 0.8425 - val_loss: 0.2538 - val_accuracy: 0.8788\n",
      "Epoch 6/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3755 - accuracy: 0.8527 - val_loss: 0.2524 - val_accuracy: 0.8687\n",
      "Epoch 7/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3375 - accuracy: 0.8720 - val_loss: 0.3409 - val_accuracy: 0.8586\n",
      "Epoch 8/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3187 - accuracy: 0.8757 - val_loss: 0.3340 - val_accuracy: 0.8586\n",
      "Epoch 9/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2911 - accuracy: 0.8895 - val_loss: 0.4911 - val_accuracy: 0.7980\n",
      "Epoch 10/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2819 - accuracy: 0.8858 - val_loss: 0.2892 - val_accuracy: 0.8485\n",
      "Epoch 11/70\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2086 - accuracy: 0.9273 - val_loss: 0.3312 - val_accuracy: 0.8586\n",
      "Epoch 12/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2303 - accuracy: 0.9125 - val_loss: 0.2898 - val_accuracy: 0.8586\n",
      "Epoch 13/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.1887 - accuracy: 0.9263 - val_loss: 0.3148 - val_accuracy: 0.8788\n",
      "Epoch 14/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.1210 - accuracy: 0.9586 - val_loss: 0.1452 - val_accuracy: 0.9293\n",
      "Epoch 15/70\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.1375 - accuracy: 0.9457 - val_loss: 0.1979 - val_accuracy: 0.8687\n",
      "Epoch 16/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.1146 - accuracy: 0.9567 - val_loss: 0.3134 - val_accuracy: 0.8889\n",
      "Epoch 17/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.0933 - accuracy: 0.9632 - val_loss: 0.2305 - val_accuracy: 0.9192\n",
      "Epoch 18/70\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.0711 - accuracy: 0.9751 - val_loss: 0.2049 - val_accuracy: 0.9293\n",
      "Training labels distribution: (array([0, 1, 2]), array([249, 444, 345], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([36, 60, 51], dtype=int64))\n",
      "Epoch 1/70\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 0.7812 - accuracy: 0.6387 - val_loss: 0.4823 - val_accuracy: 0.8435\n",
      "Epoch 2/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.5549 - accuracy: 0.7871 - val_loss: 0.4400 - val_accuracy: 0.7959\n",
      "Epoch 3/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.5029 - accuracy: 0.7861 - val_loss: 0.4499 - val_accuracy: 0.7687\n",
      "Epoch 4/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.4335 - accuracy: 0.8189 - val_loss: 0.3694 - val_accuracy: 0.8435\n",
      "Epoch 5/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.3889 - accuracy: 0.8565 - val_loss: 0.3655 - val_accuracy: 0.8299\n",
      "Epoch 6/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.3708 - accuracy: 0.8593 - val_loss: 0.3196 - val_accuracy: 0.8639\n",
      "Epoch 7/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.3159 - accuracy: 0.8815 - val_loss: 0.3783 - val_accuracy: 0.8299\n",
      "Epoch 8/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.2737 - accuracy: 0.8979 - val_loss: 0.2583 - val_accuracy: 0.8844\n",
      "Epoch 9/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.2402 - accuracy: 0.9181 - val_loss: 0.3504 - val_accuracy: 0.8707\n",
      "Epoch 10/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.2382 - accuracy: 0.9066 - val_loss: 0.3192 - val_accuracy: 0.8844\n",
      "Epoch 11/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.1872 - accuracy: 0.9268 - val_loss: 0.3446 - val_accuracy: 0.8707\n",
      "Epoch 12/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9461 - val_loss: 0.4708 - val_accuracy: 0.8095\n",
      "Epoch 13/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9547 - val_loss: 0.3810 - val_accuracy: 0.8776\n",
      "Epoch 14/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.1195 - accuracy: 0.9538 - val_loss: 0.2916 - val_accuracy: 0.9048\n",
      "Epoch 15/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.0994 - accuracy: 0.9672 - val_loss: 0.4330 - val_accuracy: 0.8571\n",
      "Epoch 16/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.1008 - accuracy: 0.9634 - val_loss: 0.5168 - val_accuracy: 0.8571\n",
      "Epoch 17/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.1363 - accuracy: 0.9432 - val_loss: 0.4146 - val_accuracy: 0.8503\n",
      "Epoch 18/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.0870 - accuracy: 0.9692 - val_loss: 0.7043 - val_accuracy: 0.8095\n",
      "Epoch 19/70\n",
      "130/130 [==============================] - 1s 10ms/step - loss: 0.0910 - accuracy: 0.9653 - val_loss: 0.3371 - val_accuracy: 0.9252\n",
      "Epoch 20/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0541 - accuracy: 0.9788 - val_loss: 0.4610 - val_accuracy: 0.8571\n",
      "Epoch 21/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0458 - accuracy: 0.9846 - val_loss: 0.4114 - val_accuracy: 0.8980\n",
      "Epoch 22/70\n",
      "130/130 [==============================] - 2s 12ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.5161 - val_accuracy: 0.8844\n",
      "Epoch 23/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0323 - accuracy: 0.9865 - val_loss: 0.5044 - val_accuracy: 0.8980\n",
      "Epoch 24/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9827 - val_loss: 0.5455 - val_accuracy: 0.8776\n",
      "Epoch 25/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.5270 - val_accuracy: 0.8844\n",
      "Epoch 26/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.4321 - val_accuracy: 0.9048\n",
      "Epoch 27/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.5419 - val_accuracy: 0.8844\n",
      "Epoch 28/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.5333 - val_accuracy: 0.8912\n",
      "Epoch 29/70\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.6154 - val_accuracy: 0.8844\n",
      "Training labels distribution: (array([0, 1, 2]), array([252, 456, 348], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([33, 48, 48], dtype=int64))\n",
      "Epoch 1/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.7882 - accuracy: 0.6449 - val_loss: 0.3737 - val_accuracy: 0.8837\n",
      "Epoch 2/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5562 - accuracy: 0.7737 - val_loss: 0.3826 - val_accuracy: 0.8915\n",
      "Epoch 3/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4866 - accuracy: 0.8049 - val_loss: 0.5625 - val_accuracy: 0.7054\n",
      "Epoch 4/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4774 - accuracy: 0.7964 - val_loss: 0.3910 - val_accuracy: 0.8527\n",
      "Epoch 5/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4627 - accuracy: 0.8201 - val_loss: 0.4011 - val_accuracy: 0.8295\n",
      "Epoch 6/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3995 - accuracy: 0.8466 - val_loss: 0.3923 - val_accuracy: 0.8295\n",
      "Epoch 7/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3757 - accuracy: 0.8523 - val_loss: 0.4351 - val_accuracy: 0.8140\n",
      "Epoch 8/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3504 - accuracy: 0.8627 - val_loss: 0.3351 - val_accuracy: 0.9147\n",
      "Epoch 9/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3217 - accuracy: 0.8646 - val_loss: 0.3333 - val_accuracy: 0.8605\n",
      "Epoch 10/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2906 - accuracy: 0.8902 - val_loss: 0.3307 - val_accuracy: 0.9147\n",
      "Epoch 11/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.2671 - accuracy: 0.9015 - val_loss: 0.3830 - val_accuracy: 0.8915\n",
      "Epoch 12/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2804 - accuracy: 0.8873 - val_loss: 0.4083 - val_accuracy: 0.7984\n",
      "Epoch 13/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.2345 - accuracy: 0.9167 - val_loss: 0.3808 - val_accuracy: 0.8682\n",
      "Epoch 14/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2266 - accuracy: 0.9138 - val_loss: 0.3445 - val_accuracy: 0.8837\n",
      "Epoch 15/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1901 - accuracy: 0.9290 - val_loss: 0.4215 - val_accuracy: 0.8682\n",
      "Epoch 16/70\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.1813 - accuracy: 0.9214 - val_loss: 0.3364 - val_accuracy: 0.8992\n",
      "Training labels distribution: (array([0, 1, 2]), array([258, 456, 354], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([27, 48, 42], dtype=int64))\n",
      "Epoch 1/70\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.8440 - accuracy: 0.5890 - val_loss: 0.8020 - val_accuracy: 0.6923\n",
      "Epoch 2/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 11ms/step - loss: 0.5155 - accuracy: 0.7893 - val_loss: 0.7615 - val_accuracy: 0.7179\n",
      "Epoch 3/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.4544 - accuracy: 0.8230 - val_loss: 0.7302 - val_accuracy: 0.7607\n",
      "Epoch 4/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.4185 - accuracy: 0.8390 - val_loss: 0.8167 - val_accuracy: 0.6752\n",
      "Epoch 5/70\n",
      "134/134 [==============================] - 2s 11ms/step - loss: 0.3846 - accuracy: 0.8380 - val_loss: 0.6798 - val_accuracy: 0.7265\n",
      "Epoch 6/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.3674 - accuracy: 0.8586 - val_loss: 0.7636 - val_accuracy: 0.7094\n",
      "Epoch 7/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.3473 - accuracy: 0.8586 - val_loss: 0.7040 - val_accuracy: 0.7436\n",
      "Epoch 8/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2866 - accuracy: 0.8904 - val_loss: 0.7944 - val_accuracy: 0.6667\n",
      "Epoch 9/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2626 - accuracy: 0.8998 - val_loss: 0.7591 - val_accuracy: 0.7009\n",
      "Epoch 10/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2347 - accuracy: 0.9092 - val_loss: 0.9857 - val_accuracy: 0.7521\n",
      "Epoch 11/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2334 - accuracy: 0.9129 - val_loss: 0.8406 - val_accuracy: 0.7521\n",
      "Epoch 12/70\n",
      "134/134 [==============================] - 2s 11ms/step - loss: 0.1950 - accuracy: 0.9316 - val_loss: 0.9479 - val_accuracy: 0.7094\n",
      "Epoch 13/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.1831 - accuracy: 0.9307 - val_loss: 1.0062 - val_accuracy: 0.6923\n",
      "Epoch 14/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.1769 - accuracy: 0.9326 - val_loss: 0.9650 - val_accuracy: 0.6667\n",
      "Epoch 15/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.1375 - accuracy: 0.9513 - val_loss: 0.9556 - val_accuracy: 0.6496\n",
      "Epoch 16/70\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.1312 - accuracy: 0.9522 - val_loss: 0.9827 - val_accuracy: 0.7607\n",
      "Epoch 17/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.1127 - accuracy: 0.9607 - val_loss: 0.9670 - val_accuracy: 0.6923\n",
      "Epoch 18/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0898 - accuracy: 0.9663 - val_loss: 0.8920 - val_accuracy: 0.7009\n",
      "Training labels distribution: (array([0, 1, 2]), array([249, 450, 363], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([36, 54, 33], dtype=int64))\n",
      "Epoch 1/70\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.8384 - accuracy: 0.6102 - val_loss: 0.6932 - val_accuracy: 0.6992\n",
      "Epoch 2/70\n",
      "133/133 [==============================] - 1s 10ms/step - loss: 0.5753 - accuracy: 0.7693 - val_loss: 0.6773 - val_accuracy: 0.6992\n",
      "Epoch 3/70\n",
      "133/133 [==============================] - 1s 10ms/step - loss: 0.4819 - accuracy: 0.8154 - val_loss: 0.5505 - val_accuracy: 0.7480\n",
      "Epoch 4/70\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 0.4449 - accuracy: 0.8202 - val_loss: 0.5061 - val_accuracy: 0.7886\n",
      "Epoch 5/70\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.4078 - accuracy: 0.8418 - val_loss: 0.5002 - val_accuracy: 0.7967\n",
      "Epoch 6/70\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3928 - accuracy: 0.8446 - val_loss: 0.6296 - val_accuracy: 0.7317\n",
      "Epoch 7/70\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 0.3356 - accuracy: 0.8785 - val_loss: 0.5500 - val_accuracy: 0.8211\n",
      "Epoch 8/70\n",
      "133/133 [==============================] - 1s 10ms/step - loss: 0.3345 - accuracy: 0.8804 - val_loss: 0.6613 - val_accuracy: 0.7236\n",
      "Epoch 9/70\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 0.2732 - accuracy: 0.9021 - val_loss: 0.6244 - val_accuracy: 0.7561\n",
      "Epoch 10/70\n",
      "133/133 [==============================] - 1s 10ms/step - loss: 0.2663 - accuracy: 0.9040 - val_loss: 0.6945 - val_accuracy: 0.7398\n",
      "Epoch 11/70\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 0.2193 - accuracy: 0.9153 - val_loss: 0.5906 - val_accuracy: 0.7642\n",
      "Epoch 12/70\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.1938 - accuracy: 0.9350 - val_loss: 0.5507 - val_accuracy: 0.8049\n",
      "Epoch 13/70\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.1628 - accuracy: 0.9473 - val_loss: 0.6651 - val_accuracy: 0.7886\n",
      "Epoch 14/70\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.1516 - accuracy: 0.9407 - val_loss: 0.5286 - val_accuracy: 0.7886\n",
      "Epoch 15/70\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.1214 - accuracy: 0.9586 - val_loss: 0.7783 - val_accuracy: 0.8049\n",
      "Epoch 16/70\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.1263 - accuracy: 0.9548 - val_loss: 0.7009 - val_accuracy: 0.7561\n",
      "Epoch 17/70\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.0863 - accuracy: 0.9765 - val_loss: 0.8268 - val_accuracy: 0.7805\n",
      "Epoch 18/70\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.1025 - accuracy: 0.9567 - val_loss: 0.6593 - val_accuracy: 0.7805\n",
      "Epoch 19/70\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 1.1678 - val_accuracy: 0.7642\n",
      "Training labels distribution: (array([0, 1, 2]), array([252, 462, 354], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([33, 42, 42], dtype=int64))\n",
      "Epoch 1/70\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.8314 - accuracy: 0.6011 - val_loss: 0.8067 - val_accuracy: 0.6496\n",
      "Epoch 2/70\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.5402 - accuracy: 0.7809 - val_loss: 0.7583 - val_accuracy: 0.7607\n",
      "Epoch 3/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.4659 - accuracy: 0.8249 - val_loss: 0.7053 - val_accuracy: 0.7521\n",
      "Epoch 4/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.4318 - accuracy: 0.8418 - val_loss: 0.7200 - val_accuracy: 0.7778\n",
      "Epoch 5/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.3901 - accuracy: 0.8493 - val_loss: 0.5767 - val_accuracy: 0.7607\n",
      "Epoch 6/70\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.3735 - accuracy: 0.8633 - val_loss: 0.7490 - val_accuracy: 0.7094\n",
      "Epoch 7/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.3347 - accuracy: 0.8764 - val_loss: 0.5929 - val_accuracy: 0.7607\n",
      "Epoch 8/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2989 - accuracy: 0.8933 - val_loss: 0.6031 - val_accuracy: 0.7436\n",
      "Epoch 9/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2790 - accuracy: 0.8998 - val_loss: 0.8394 - val_accuracy: 0.6838\n",
      "Epoch 10/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2675 - accuracy: 0.8970 - val_loss: 0.7040 - val_accuracy: 0.7436\n",
      "Epoch 11/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2378 - accuracy: 0.9195 - val_loss: 0.6918 - val_accuracy: 0.7692\n",
      "Epoch 12/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2472 - accuracy: 0.9110 - val_loss: 0.6658 - val_accuracy: 0.7692\n",
      "Epoch 13/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.2072 - accuracy: 0.9316 - val_loss: 0.4926 - val_accuracy: 0.8120\n",
      "Epoch 14/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9363 - val_loss: 0.6277 - val_accuracy: 0.7863\n",
      "Epoch 15/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9419 - val_loss: 0.3770 - val_accuracy: 0.8291\n",
      "Epoch 16/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.1342 - accuracy: 0.9597 - val_loss: 0.3903 - val_accuracy: 0.8632\n",
      "Epoch 17/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.1384 - accuracy: 0.9513 - val_loss: 0.5535 - val_accuracy: 0.7949\n",
      "Epoch 18/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.1111 - accuracy: 0.9654 - val_loss: 0.4194 - val_accuracy: 0.8803\n",
      "Epoch 19/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.1168 - accuracy: 0.9625 - val_loss: 0.4114 - val_accuracy: 0.8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0897 - accuracy: 0.9757 - val_loss: 0.7485 - val_accuracy: 0.7778\n",
      "Epoch 21/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.9794 - val_loss: 0.6060 - val_accuracy: 0.8376\n",
      "Epoch 22/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0963 - accuracy: 0.9691 - val_loss: 0.5308 - val_accuracy: 0.8376\n",
      "Epoch 23/70\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.4319 - val_accuracy: 0.8803\n",
      "Epoch 24/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0875 - accuracy: 0.9719 - val_loss: 0.5142 - val_accuracy: 0.8291\n",
      "Epoch 25/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0658 - accuracy: 0.9860 - val_loss: 0.5171 - val_accuracy: 0.8632\n",
      "Epoch 26/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.7396 - val_accuracy: 0.8034\n",
      "Epoch 27/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0525 - accuracy: 0.9860 - val_loss: 0.4840 - val_accuracy: 0.8889\n",
      "Epoch 28/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0269 - accuracy: 0.9953 - val_loss: 0.4830 - val_accuracy: 0.8376\n",
      "Epoch 29/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0247 - accuracy: 0.9953 - val_loss: 0.6010 - val_accuracy: 0.8205\n",
      "Epoch 30/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.8247 - val_accuracy: 0.7949\n",
      "Epoch 31/70\n",
      "134/134 [==============================] - 1s 11ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 0.6652 - val_accuracy: 0.8291\n",
      "Training labels distribution: (array([0, 1, 2]), array([258, 444, 354], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([27, 60, 42], dtype=int64))\n",
      "Epoch 1/70\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.7817 - accuracy: 0.6288 - val_loss: 0.5699 - val_accuracy: 0.8140\n",
      "Epoch 2/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5861 - accuracy: 0.7670 - val_loss: 0.6846 - val_accuracy: 0.7597\n",
      "Epoch 3/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5206 - accuracy: 0.7898 - val_loss: 0.4599 - val_accuracy: 0.7907\n",
      "Epoch 4/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4929 - accuracy: 0.8011 - val_loss: 0.4263 - val_accuracy: 0.8062\n",
      "Epoch 5/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4462 - accuracy: 0.8163 - val_loss: 0.4807 - val_accuracy: 0.8217\n",
      "Epoch 6/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4350 - accuracy: 0.8286 - val_loss: 0.3807 - val_accuracy: 0.8527\n",
      "Epoch 7/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4064 - accuracy: 0.8381 - val_loss: 0.4240 - val_accuracy: 0.8372\n",
      "Epoch 8/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3638 - accuracy: 0.8551 - val_loss: 0.4710 - val_accuracy: 0.8450\n",
      "Epoch 9/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3522 - accuracy: 0.8523 - val_loss: 0.4126 - val_accuracy: 0.8062\n",
      "Epoch 10/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3318 - accuracy: 0.8627 - val_loss: 0.5823 - val_accuracy: 0.8372\n",
      "Epoch 11/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3256 - accuracy: 0.8655 - val_loss: 0.4832 - val_accuracy: 0.8372\n",
      "Epoch 12/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.2748 - accuracy: 0.8892 - val_loss: 0.5237 - val_accuracy: 0.7984\n",
      "Epoch 13/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.2334 - accuracy: 0.9119 - val_loss: 0.5466 - val_accuracy: 0.8217\n",
      "Epoch 14/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.2174 - accuracy: 0.9167 - val_loss: 0.4761 - val_accuracy: 0.8682\n",
      "Epoch 15/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.2258 - accuracy: 0.9176 - val_loss: 0.4397 - val_accuracy: 0.8062\n",
      "Epoch 16/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1844 - accuracy: 0.9290 - val_loss: 0.4162 - val_accuracy: 0.8760\n",
      "Epoch 17/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1771 - accuracy: 0.9384 - val_loss: 0.5512 - val_accuracy: 0.7984\n",
      "Epoch 18/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9403 - val_loss: 0.6035 - val_accuracy: 0.7984\n",
      "Epoch 19/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1590 - accuracy: 0.9460 - val_loss: 0.5632 - val_accuracy: 0.8527\n",
      "Epoch 20/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1299 - accuracy: 0.9564 - val_loss: 0.6598 - val_accuracy: 0.8527\n",
      "Epoch 21/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1424 - accuracy: 0.9460 - val_loss: 0.7826 - val_accuracy: 0.8450\n",
      "Epoch 22/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1198 - accuracy: 0.9612 - val_loss: 0.6462 - val_accuracy: 0.8682\n",
      "Epoch 23/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0950 - accuracy: 0.9621 - val_loss: 0.5802 - val_accuracy: 0.8837\n",
      "Epoch 24/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0877 - accuracy: 0.9678 - val_loss: 0.6725 - val_accuracy: 0.8605\n",
      "Epoch 25/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.6159 - val_accuracy: 0.8760\n",
      "Epoch 26/70\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.9754 - val_loss: 0.6364 - val_accuracy: 0.8915\n",
      "Epoch 27/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0463 - accuracy: 0.9830 - val_loss: 0.7908 - val_accuracy: 0.8837\n",
      "Epoch 28/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.9659 - val_loss: 0.6265 - val_accuracy: 0.8605\n",
      "Epoch 29/70\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0596 - accuracy: 0.9773 - val_loss: 0.6849 - val_accuracy: 0.8915\n",
      "Training labels distribution: (array([0, 1, 2]), array([264, 459, 369], dtype=int64))\n",
      "Testing labels distribution: (array([0, 1, 2]), array([21, 45, 27], dtype=int64))\n",
      "Epoch 1/70\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.8433 - accuracy: 0.5778 - val_loss: 0.6475 - val_accuracy: 0.6989\n",
      "Epoch 2/70\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.5563 - accuracy: 0.7656 - val_loss: 0.5330 - val_accuracy: 0.7527\n",
      "Epoch 3/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.4897 - accuracy: 0.7921 - val_loss: 0.4955 - val_accuracy: 0.8495\n",
      "Epoch 4/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.4163 - accuracy: 0.8443 - val_loss: 0.4724 - val_accuracy: 0.7849\n",
      "Epoch 5/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.3712 - accuracy: 0.8544 - val_loss: 0.4055 - val_accuracy: 0.7957\n",
      "Epoch 6/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.3342 - accuracy: 0.8828 - val_loss: 0.3397 - val_accuracy: 0.8280\n",
      "Epoch 7/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.2967 - accuracy: 0.8919 - val_loss: 0.3981 - val_accuracy: 0.8710\n",
      "Epoch 8/70\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.2520 - accuracy: 0.9093 - val_loss: 0.3107 - val_accuracy: 0.8602\n",
      "Epoch 9/70\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.2010 - accuracy: 0.9267 - val_loss: 0.4764 - val_accuracy: 0.8710\n",
      "Epoch 10/70\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.1838 - accuracy: 0.9368 - val_loss: 0.3650 - val_accuracy: 0.8925\n",
      "Epoch 11/70\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.1600 - accuracy: 0.9524 - val_loss: 0.4290 - val_accuracy: 0.8387\n",
      "Epoch 12/70\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.1271 - accuracy: 0.9551 - val_loss: 0.4757 - val_accuracy: 0.8602\n",
      "Epoch 13/70\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.1350 - accuracy: 0.9487 - val_loss: 0.4149 - val_accuracy: 0.8387\n",
      "Epoch 14/70\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 0.1030 - accuracy: 0.9670 - val_loss: 0.5172 - val_accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/70\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.3812 - val_accuracy: 0.8817\n",
      "Epoch 16/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.4274 - val_accuracy: 0.8602\n",
      "Epoch 17/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.0830 - accuracy: 0.9771 - val_loss: 0.4633 - val_accuracy: 0.8710\n",
      "Epoch 18/70\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.5579 - val_accuracy: 0.7849\n",
      "Best validation accuracy: 0.9292929172515869\n",
      "[0.9090909361839294, 0.8863636255264282, 0.9292929172515869, 0.9251700639724731, 0.9147287011146545, 0.7606837749481201, 0.8211382031440735, 0.8888888955116272, 0.8914728760719299, 0.8924731016159058]\n",
      "Mean validation accuracy: 0.8819303095340729\n",
      "Mean accuracy for 10-fold: 0.8819303095340729\n",
      "-------------------------DONE------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracy_results_10fold = cross_validation_training(k_fold=10)\n",
    "print('Mean accuracy for 10-fold: %s' % np.mean(accuracy_results_10fold))\n",
    "print(\"-------------------------DONE------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8458b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
